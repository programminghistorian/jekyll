<!DOCTYPE html>
<!-- paulirish.com/2008/conditional-stylesheets-vs-css-hacks-answer-neither/ --><!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]--><!--[if IE 7]><html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]--><!--[if IE 8]><html class="no-js lt-ie9" lang="en"> <![endif]--><!--[if gt IE 8]><!--><html class="no-js" lang="en"><!--<![endif]--><head><meta charset="utf-8"/><title>The Programming Historian</title><!-- Mobile viewport optimized: h5bp.com/viewport --><meta content="width=device-width" name="viewport"/><link href="http://fonts.googleapis.com/css?family=Lato:300,700|Crete+Round" rel="stylesheet" type="text/css"/><link href="http://programminghistorian.org/wp-content/themes/ph-wp-theme/style.css" rel="stylesheet"/><!-- Modernizr and Friends --><script src="http://programminghistorian.org/wp-content/themes/ph-wp-theme/javascripts/modernizr.min.js"></script><script>
      Modernizr.load([
        {
          test: Modernizr.mq(),
          nope: ['http://programminghistorian.org/wp-content/themes/ph-wp-theme/javascripts/respond.min.js',
          'http://programminghistorian.org/wp-content/themes/ph-wp-theme/javascripts/selectivizr.min.js']
        }
      ]);
    </script><script type="text/javascript">//&lt;![CDATA[
            // Google Analytics for WordPress by Yoast v4.3.5 | http://yoast.com/wordpress/google-analytics/
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-2752866-8']);
				            _gaq.push(['_setCustomVar',2,'author','seth-van-hooland',3],['_trackPageview']);
            (function () {
                var ga = document.createElement('script');
                ga.type = 'text/javascript';
                ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';

                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(ga, s);
            })();
            //]]&gt;</script><link href="http://programminghistorian.org/lessons/cleaning-data-with-openrefine/feed" rel="alternate" title="The Programming Historian » Cleaning Data with OpenRefine Comments Feed" type="application/rss+xml"/><script src="http://programminghistorian.org/wp-includes/js/jquery/jquery.js?ver=1.11.0" type="text/javascript"></script><script src="http://programminghistorian.org/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1" type="text/javascript"></script><script src="http://programminghistorian.org/wp-content/themes/ph-wp-theme/javascripts/bigfoot.min.js?ver=3.9.1" type="text/javascript"></script><link href="http://programminghistorian.org/xmlrpc.php?rsd" rel="EditURI" title="RSD" type="application/rsd+xml"/><link href="http://programminghistorian.org/wp-includes/wlwmanifest.xml" rel="wlwmanifest" type="application/wlwmanifest+xml"/><link href="http://programminghistorian.org/lessons/understanding-regular-expressions" rel="prev" title="Understanding Regular Expressions"/><link href="http://programminghistorian.org/lessons/applied-archival-downloading-with-wget" rel="next" title="Applied Archival Downloading with Wget"/><meta content="WordPress 3.9.1" name="generator"/><link href="http://programminghistorian.org/lessons/cleaning-data-with-openrefine" rel="canonical"/><link href="http://programminghistorian.org/?p=1940" rel="shortlink"/><style id="syntaxhighlighteranchor" type="text/css"></style><meta content="Seth van Hooland, Ruben Verborgh, Max De Wilde" name="author"/><meta content="Cleaning Data with OpenRefine" name="title"/><meta content="2013-08-05" name="date"/><meta content="Adam Crymble, Patrick Burns, Nora McGregor" name="reviewers"/><meta content="default" name="layout"/></head><body class="single single-lesson postid-1940">
<!-- Prompt IE 6 users to install Chrome Frame. Remove this if you support IE 6.
       chromium.org/developers/how-tos/chrome-frame-getting-started -->
<!--[if lt IE 7]><p class=chromeframe>Your browser is <em>ancient!</em> <a href="http://browsehappy.com/">Upgrade to a different browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to experience this site.</p><![endif]-->

<script type="text/javascript">
    jQuery(document).ready(function($) {
    // Inside of this function, $() will work as an alias for jQuery()
    // and other libraries also using $ will not be accessible under this shortcut
        $.bigfoot();
    });
    </script>
<div role="main">
<article>

<div class="content">
<p style="text-align: left;"><strong>Lesson goals</strong></p>
<p>Don’t take your data at face value. That is the key message of this tutorial which focuses on how scholars can diagnose and act upon the accuracy of data. In this lesson, you will learn the principles and practice of data cleaning, as well as how <a href="http://openrefine.org" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://openrefine.org']);" target="_blank" title="OpenRefine"><code>OpenRefine</code></a> can be used to perform four essential tasks that will help you to clean your data:</p>
<ol>
<li>Remove duplicate records</li>
<li>Separate multiple values contained in the same field</li>
<li>Analyse the distribution of values throughout a data set</li>
<li>Group together different representations of the same reality</li>
</ol>
<p>These steps are illustrated with the help of a series of exercises based on a collection of metadata from the <a href="http://www.powerhousemuseum.com" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.powerhousemuseum.com']);" target="_blank" title="Powerhouse museum">Powerhouse museum</a>, demonstrating how (semi-)automated methods can help you correct the errors in your data.</p>
<p><strong>Why should historians care about data quality?</strong></p>
<p>Duplicate records, empty values and inconsistent formats are phenomena we should be prepared to deal with when using historical data sets. This lesson will teach you how to discover inconsistencies in data contained within a spreadsheet or a database. As we increasingly share, aggregate and reuse data on the web, historians will need to respond to data quality issues which inevitably pop up. Using a program called <code>OpenRefine</code>, you will be able to easily identify systematic errors such as blank cells, duplicates, spelling inconsistencies, etc. <code>OpenRefine</code> not only allows you to quickly diagnose the accuracy of your data, but also to act upon certain errors in an automated manner.</p>
<p><strong>Description of the tool: OpenRefine</strong></p>
<p><strong></strong>In the past, historians had to rely on information technology specialists to diagnose data quality and to run cleaning tasks. This required custom computer programs when working with sizeable data sets. Luckily, the advent of <span class="tech">Interactive Data Transformation</span> tools (IDTs) now allows for rapid and inexpensive operations on large amounts of data, even by professionals lacking in-depth technical skills.</p>
<p>IDTs resemble the desktop spreadsheet software we are all familiar with, and they share some common functionalities. You can for example use an application such as Microsoft Excel to sort your data based on numerical, alphabetical and custom-developed filters, which allows you to detect errors more easily. Setting up these filters in a spreadsheet can be cumbersome, as they are a secondary functionality. On a more general level, we could say that spreadsheets are designed to work on individual rows and cells, whereas IDTs operate on large ranges of data at once. These ‘spreadsheets on steroids’ offer an integrated and user-friendly interface through which end users can detect and correct errors.</p>
<p>Several general purpose tools for interactive data transformation have been developed in recent years, such as <a href="http://control.cs.berkeley.edu/abc/" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://control.cs.berkeley.edu']);" target="_blank" title="Potter's Wheel ABC "><code>Potter’s Wheel ABC</code></a> and <a href="http://vis.stanford.edu/papers/wrangler/" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://vis.stanford.edu']);" target="_blank" title="Wrangler"><code>Wrangler</code></a>. Here we want to focus specifically on <a href="http://openrefine.org" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://openrefine.org']);" target="_blank" title="OpenRefine"><code>OpenRefine</code></a> (formerly Freebase Gridworks and Google Refine), as in the opinion of the authors, it is the most user-friendly tool to efficiently process and clean large amounts of data in a browser-based interface.</p>
<p>On top of <a href="http://en.wikipedia.org/wiki/Data_profiling" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank"><span class="tech">data profiling</span></a> and cleaning operations, <code>OpenRefine</code> extensions allow users to identify concepts in unstructured text, a process referred to as <a href="http://en.wikipedia.org/wiki/Named-entity_recognition" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank"><span class="tech">named-entity recognition</span></a> (NER), and can also reconcile their own data with existing knowledge bases. By doing so, <code>OpenRefine</code> can be a practical tool to link data with concepts and authorities which have already been declared on the Web by parties such as <a href="http://www.loc.gov/index.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.loc.gov']);" target="_blank" title="Library of Congress">Library of Congress</a> or <a href="http://www.oclc.org/home.en.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.oclc.org']);" target="_blank" title="OCLC">OCLC</a>. Data cleaning is a prerequisite to these steps; the success rate of NER and a fruitful matching process between your data and external authorities depends on your ability to make your data as coherent as possible.</p>
<p><strong>Description of the exercise: Powerhouse Museum</strong></p>
<p><strong></strong>The Powerhouse Museum in Sydney provides a freely available metadata export of its collection on its <a href="http://www.powerhousemuseum.com/collection/database/download.php" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.powerhousemuseum.com']);" target="_blank" title="website">website</a>. The museum is one of the largest science and technology museums worldwide, providing access to almost 90,000 objects, ranging from steam engines to fine glassware and from haute couture to computer chips.</p>
<p>The Powerhouse has been very actively disclosing its collection online and making most of its data freely available. From the museum website, a tab-separated text file under the name <code>phm-collection.tsv</code> can be downloaded, which you can open as a spreadsheet. The unzipped file (58MB) contains basic metadata (17 fields) for 75,823 objects, released under a <a href="http://creativecommons.org/licenses/by-nc/2.5/au/" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://creativecommons.org']);" target="_blank">Creative Commons Attribution Share Alike (CCASA) license</a>. In this tutorial we will be using a copy of the data that we have archived for you to download (in a moment). This ensures that if the Powerhouse Museum updates the data, you will still be able to follow along with the Lesson.</p>
<p>Throughout the data profiling and cleaning process, the case study will specifically focus on the <em>Categories</em> field, which is populated with terms from the Powerhouse museum Object Names Thesaurus (PONT). PONT recognizes Australian usage and spelling, and reflects in a very direct manner the strengths of the collection. In the collection you will find better representations of social history and decorative arts, and comparably few object names relating to fine arts and natural history.</p>
<p>The terms in the Categories field comprise what we call a <a href="http://en.wikipedia.org/wiki/Controlled_vocabulary" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank"><span class="tech">Controlled vocabulary</span></a>. A controlled vocabulary consists of keywords describing the content of a collection using a limited number of terms, and is often a key entry point into data sets used by historians in libraries, archives and museums. That is why we will give particular attention to the ‘Categories’ field. Once the data has been cleaned, it should be possible to reuse the terms in the controlled vocabulary to find additional information about the terms elsewhere online, which is known as creating <a href="http://en.wikipedia.org/wiki/Linked_data" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank">Linked Data</a>.</p>
<p><strong>Getting started: installing OpenRefine and importing data</strong></p>
<p><a href="http://openrefine.org/#download_openrefine" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://openrefine.org']);" target="_blank">Download OpenRefine</a> and follow the installation instructions. OpenRefine works on all platforms: Windows, Mac, and Linux. <code>OpenRefine</code> will open in your browser, but it is important to realise that the application is run locally and that your data won’t be stored online. The data files are available on our <a href="http://data.freeyourmetadata.org/powerhouse-museum/" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://data.freeyourmetadata.org']);" target="">FreeYourMetadata website</a>, which will be used throughout this tutorial. Please download the <code>phm-collection.tsv</code> file before continuing (also archived on the Programming Historian site: as <a href="http://dev.programminghistorian.org/wp-content/uploads/2013/08/phm-collection.tsv">phm-collection</a>).</p>
<p>On the <code>OpenRefine</code> start page, create a new project using the downloaded data file and click <code>Next</code>. By default, the first line will be correctly parsed as the name of a column, but you need to unselect the ‘Quotation marks are used to enclose cells containing column separators’ checkbox, since the quotes inside the file do not have any meaning to <code>OpenRefine</code>. Now click on ‘<code>Create project</code>‘. If all goes well, you will see 75,814 rows. Alternatively, you can download the <a href="http://data.freeyourmetadata.org/powerhouse-museum/phm-collection.google-refine.tar.gz" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://data.freeyourmetadata.org']);" target="_blank">initial OpenRefine project</a> directly.</p>
<p>The Powerhouse museum data set consists of detailed metadata on all the collection objects, including title, description, several categories the item belongs to, provenance information, and a persistent link to the object on the museum website. To get an idea of what object the metadata corresponds to, simply click the persistent link and the website will open.</p>
<p><img alt="Powerhouse Museum Website" class="aligncenter size-full wp-image-2094" src="http://programminghistorian.org/wp-content/uploads/2013/08/powerhouseScreenshot.png" width="640"/>
<p>Figure 1: Screenshot of a Sample Object on the Powerhouse Museum Website</p></p>
<p><strong>Get to know your data</strong></p>
<p>The first thing to do is to look around and get to know your data. You can inspect the different data values by displaying them in <span class="tech">facets</span>. You could consider a <a href="http://en.wikipedia.org/wiki/Faceted_search" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank">facet</a> like a lense through which you view a specific subset of the data, based on a criterion of your choice. Click the triangle in front of the column name, select Facet, and create a facet. For instance, try a ‘Text’ facet or a ‘Numeric’ facet, depending on the nature of the values contained in the fields (numeric values are in green). Be warned, however, that text facets are best used on fields with redundant values (Categories for instance); if you run into a ‘too many to display’ error, you can choose to raise the choice count limit above the 2,000 default, but too high a limit can slow down the application (5,000 is usually a safe choice). Numeric facets do not have this restriction. For more options, select Customized facets: facet by blank, for instance, comes handy to find out how many values were filled in for each field. We’ll explore these further in the following exercises.</p>
<p><strong>Remove blank rows</strong></p>
<p>One thing you notice when creating a numeric facet for the Record ID column, is that three rows are empty. You can find them by unselecting the Numeric checkbox, leaving only Non-numeric values. Actually, these values are not really blank but contain a single whitespace character, which can be seen by moving your cursor to where the value should have been and clicking the ‘edit’ button that appears. To remove these rows, click the triangle in front of the first column called ‘All’, select ‘Edit rows’, and then ‘Remove all matching rows’. Close the numeric facet to see the remaining 75,811 rows.</p>
<p><strong>Removing duplicates</strong></p>
<p>A second step is to detect and remove duplicates. These can be spotted by sorting them by a unique value, such as the Record ID (in this case we are assuming the Record ID should in fact be unique for each entry). The operation can be performed by clicking the triangle left of Record ID, then choosing ‘Sort’… and selecting the ‘numbers’ bullet. In <code>OpenRefine</code>, sorting is only a visual aid, unless you make the reordering permanent. To do this, click ‘the’ Sort menu that has just appeared at the top and choose ‘Reorder rows permanently’. If you forget to do this, you will get unpredictable results later in this tutorial.</p>
<p>Identical rows are now adjacent to each other. Next, blank the Record ID of rows that have the same Record ID as the row above them, marking them duplicates. To do this, click on the Record ID triangle, choose ‘Edit cells’ &gt; ‘Blank down’. The status message tells you that 84 columns were affected (if you forgot to reorder rows permanently, you will get only 19; if so, undo the blank down operation in the ‘Undo/Redo’ tab and go back to the previous paragraph to make sure that rows are reordered and not simply sorted). Eliminate those rows by creating a facet on ‘blank cells’ in the Record ID column (‘Facet’ &gt; ‘Customized facets’ &gt; ‘Facet by blank’), selecting the 84 blank rows by clicking on ‘true’, and removing them using the ‘All’ triangle (‘Edit rows’ &gt; ‘Remove all matching rows’). Upon closing the facet, you see 75,727 unique rows.</p>
<p>Be aware that special caution is needed when eliminating duplicates. In the above mentioned step, we assume the dataset has a field with unique values, indicating that the entire row represents a duplicate. This is not necessarily the case, and great caution should be taken to manually verify wether the entire row represents a duplicate or not.</p>
<p><strong>Atomization</strong></p>
<p>Once the duplicate records have been removed, we can have a closer look at the <em>Categories</em> field. On average each object has been attributed 2.25 categories. These categories are contained within the same field, separated by a pipe character ‘|’. Record 9, for instance, contains three: ‘Mineral samples|Specimens|Mineral Samples-Geological’. In order to analyze in detail the use of the keywords, the values of the Categories field need to be split up into individual cells on the basis of the pipe character , expanding the 75,727 records into 170,167 rows. Choose ‘Edit cells’, ‘Split multi-valued cells’, entering ‘|’ as the value separator. OpenRefine informs you that you now have 170,167 rows.</p>
<p>It is important to fully understand the rows/records paradigm. Make the Record ID column visible to see what is going on. You can switch between ‘rows’ and ‘records’ view by clicking on the so-labelled links just above the column headers. In the ‘rows view’, each row represents a couple of Record IDs and a single Category, enabling manipulation of each one individually. The ‘records view’ has an entry for each Record ID, which can have different categories on different rows (grouped together in grey or white), but each record is manipulated as a whole. Concretely, there now are 170,167 category assignments (rows), spread over 75,736 collection items (records). You maybe noticed that we are 9 records up from the original 75,727, but don’t worry about that for the time being, we will come back to this small difference later.</p>
<p><strong>Facetting and clustering</strong></p>
<p>Once the content of a field has been properly atomized, filters, facets, and clusters can be applied to give a quick and straightforward overview of classic metadata issues. By applying the customized facet ‘Facet by blank’, one can immediately identify the 461 records that do not have a category, representing 0.6% of the collection. Applying a text facet to the Categories field allows an overview of the 4,934 different categories used in the collection (the default limit being 2,000, you can click ‘Set choice count limit’ to raise it to 5,000). The headings can be sorted alphabetically or by frequency (‘count’), giving a list of the most used terms to index the collection. The top three headings are ‘Numismatics’ (8,041), ‘Ceramics’ (7,390) and ‘Clothing and dress’ (7,279).</p>
<p>After the application of a facet, <code>OpenRefine</code> proposes to cluster facet choices together based on various similarity methods. As Figure 2 illustrates, the clustering allows you to solve issues regarding case inconsistencies, incoherent use of either the singular or plural form, and simple spelling mistakes. <code>OpenRefine</code> presents the related values and proposes a merge into the most recurrent value. Select values you wish to cluster by selecting their boxes individually or by clicking ‘Select all’ at the bottom, then chose ‘Merge Selected and Re-Cluster’.</p>
<p><img alt="Screenshot of OpenRefine Example" class="aligncenter size-full wp-image-2095" src="http://programminghistorian.org/wp-content/uploads/2013/08/overviewOfSomeClusters.png" width="860"/> <p>Figure 2 : Overview of some clusters</p></p>
<p>The default clustering method is not too complicated, so it does not find all clusters yet. Experiment with different methods to see what results they yield. Be careful though: some methods are too aggressive, so you might end up clustering values that do not belong together. Now that the values have been clustered individually, we can put them back together in a single cell. Click the Categories triangle and choose Edit cells, Join multi-valued cells, OK. Choose the pipe character as a separator. The rows now look like before, with a multi-valued Categories field.</p>
<p><strong>Applying ad-hoc transformations through the use of regular expressions</strong></p>
<p>You may remember there was an increase in the number of records after the splitting process: nine records appeared out of nowhere. In order to find the cause of this disparity, we need to go back in time before we split the categories into separate rows. To do so, toggle the Undo/Redo tab right of the Facet/Filter tab, and you will get a history of all the actions that you performed since the project was created. Select the step just before ‘Split multi-valued cells in column Categories’ (if you followed our example this should be ‘Remove 84 rows’) then go back to the Facet/Filter tab.</p>
<p>The issue arose during the splitting operation on the pipe character, so there is a strong chance that whatever went wrong is linked to this character. Let’s apply a filter on the Categories column by selecting ‘Text filter’ in the menu. First type a single <code>|</code> in the field on the left: <code>OpenRefine</code> informs you that there are 71,064 matching records (i.e. records containing a pipe) out of a total of 75,727. Cells that do not contain a pipe can be blank ones, but also cells containing a single category with no separator, such as record 29 which only has ‘Scientific instruments’.</p>
<p>Now enter a second <code>|</code> after the first one to get || (double pipe): you can see that 9 records are matching this pattern. These are likely the 9 records guilty of our discrepancy: when <code>OpenRefine</code> splits these up, the double pipe is interpreted as a break between two records instead of a meaningless double separator. Now how do we correct these values? Go to the menu of the ‘Categories’ field, and choose ‘Edit cells’ &gt; ‘Transform’…. Welcome to the custom text tranform interface, a powerful functionality of <code>OpenRefine</code> using the <code>OpenRefine</code> Expression Language (GREL).</p>
<p>The word ‘value’ in the text field represents the current value of each cell, which you can see below. We can modify this value by applying functions to it (see the <a href="https://github.com/OpenRefine/OpenRefine/wiki/GREL-Functions" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://github.com']);" target="_blank">GREL documentation</a> for a full list). In this case, we want to replace double pipes with a single pipe. This can be achieved by entering the following <a href="http://en.wikipedia.org/wiki/Regular_expression" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank" title="Regular Expressions">regular expression</a> (be sure not to forget the quotes):</p>
<pre class="brush: plain; title: ; notranslate" title="">value.replace('||', '|')</pre>
<p>Under the ‘Expression’ text field, you get a preview of the modified values, with double pipes removed. Click OK and try again to split the categories with ‘Edit cells’ &gt; ‘Split multi-valued cells’, the number of records will now stay at 75,727 (click the ‘records’ link to double-check).</p>
<p>* * *<br/>
Another issue that can be solved with the help of GREL is the problem of records for which the same category is listed twice. Take record 41 for instance, whose categories are ‘Models|Botanical specimens|Botanical Specimens|Didactic Displays|Models’. The category ‘Models’ appears twice without any good reason, so we want to remove this duplicate. Click the Categories triangle and choose Edit cells, Join multi-valued cells, OK. Choose the pipe character as a separator. Now the categories are listed as before. Then select ‘Edit cells’ &gt; ‘Transform’, also on the categories column. Using GREL we can successively split the categories on the pipe character, look for unique categories and join them back again. To achieve this, just type the following expression:</p>
<pre class="brush: plain; title: ; notranslate" title="">value.split('|').uniques().join('|')</pre>
<p>You will notice that 32,599 cells are affected, more than half the collection.</p>
<p><strong>Exporting your cleaned data</strong></p>
<p>Since you first loaded your data into <code>OpenRefine</code>, all cleaning operations have been performed in the software memory, leaving your original data set untouched. If you want to save the data that you have been cleaning, you need to export them by clicking on the ‘Export’ menu top-right of the screen. <code>OpenRefine</code> supports a large variety of formats, such as <a href="http://en.wikipedia.org/wiki/Comma-separated_values" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://en.wikipedia.org']);" target="_blank">CSV</a>, HTML or Excel: select whatever suits you best or add your own export template by clicking ‘Templating’. You can also export your project in the internal <code>OpenRefine</code> format in order to share it with others.</p>
<p><strong>Building on top of your cleaned data</strong></p>
<p>Once your data has been cleaned, you can take the next step and explore other exciting features of <code>OpenRefine</code>. The user community of <code>OpenRefine</code> has developed two particularly interesting extensions which allow you to link your data to data that has already been published on the Web. The <a href="http://refine.deri.ie/docs" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://refine.deri.ie']);" target="_blank">RDF Refine extension</a> transforms plaintext keywords into URLs. The <a href="https://github.com/RubenVerborgh/Refine-NER-Extension" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://github.com']);" target="_blank">NER extension</a> allows you to apply named-entity recognition (NER), which identifies keywords in flowing text and gives them a URL.</p>
<p><strong>Conclusions</strong></p>
<p>If you only remember on thing from this lesson, it should be this: <em>all data is dirty, but you can do something about it.</em> As we have shown here, there is already a lot you can do yourself to increase data quality significantly. First of all, you have learned how you can get a quick overview of how many empty values your dataset contains and how often a particular value (e.g. a keyword) is used throughout a collection. This lessons also demonstrated how to solve recurrent issues such as duplicates and spelling inconsistencies in an automated manner with the help of <code>OpenRefine</code>. Don’t hesitate to experiment with the cleaning features, as you’re performing these steps on a copy of your data set, and <code>OpenRefine</code> allows you to trace back all of your steps in the case you have made an error.</p>

<!-- You can start editing here. -->

<div class="navigation">
<div class="alignleft"></div>
<div class="alignright"></div>
</div>

<div class="navigation">
<div class="alignleft"></div>
<div class="alignright"></div>
</div>

</div>
</article>
<!-- .navigation -->
</div>

<script src="http://programminghistorian.org/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/scripts/shCore.js?ver=3.0.83c" type="text/javascript"></script>
<script src="http://programminghistorian.org/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/scripts/shBrushPlain.js?ver=3.0.83c" type="text/javascript"></script>
<script type="text/javascript">
	(function(){
		var corecss = document.createElement('link');
		var themecss = document.createElement('link');
		var corecssurl = "http://programminghistorian.org/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shCore.css?ver=3.0.83c";
		if ( corecss.setAttribute ) {
				corecss.setAttribute( "rel", "stylesheet" );
				corecss.setAttribute( "type", "text/css" );
				corecss.setAttribute( "href", corecssurl );
		} else {
				corecss.rel = "stylesheet";
				corecss.href = corecssurl;
		}
		document.getElementsByTagName("head")[0].insertBefore( corecss, document.getElementById("syntaxhighlighteranchor") );
		var themecssurl = "http://programminghistorian.org/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shThemeDefault.css?ver=3.0.83c";
		if ( themecss.setAttribute ) {
				themecss.setAttribute( "rel", "stylesheet" );
				themecss.setAttribute( "type", "text/css" );
				themecss.setAttribute( "href", themecssurl );
		} else {
				themecss.rel = "stylesheet";
				themecss.href = themecssurl;
		}
		//document.getElementById("syntaxhighlighteranchor").appendChild(themecss);
		document.getElementsByTagName("head")[0].insertBefore( themecss, document.getElementById("syntaxhighlighteranchor") );
	})();
	SyntaxHighlighter.config.strings.expandSource = '+ expand source';
	SyntaxHighlighter.config.strings.help = '?';
	SyntaxHighlighter.config.strings.alert = 'SyntaxHighlighter\n\n';
	SyntaxHighlighter.config.strings.noBrush = 'Can\'t find brush for: ';
	SyntaxHighlighter.config.strings.brushNotHtmlScript = 'Brush wasn\'t configured for html-script option: ';
	SyntaxHighlighter.defaults['pad-line-numbers'] = false;
	SyntaxHighlighter.defaults['toolbar'] = false;
	SyntaxHighlighter.all();
</script>
</body></html>