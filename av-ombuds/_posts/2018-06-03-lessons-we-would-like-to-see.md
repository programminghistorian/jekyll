---
title: The Seven More Lessons No One's Yet Written (but need writing)
authors:
- Adam Crymble
layout: post
categories: posts
---

<p><figure><a href="/images/call-to-action/call-to-action.jpg">
        <img src="/images/call-to-action/call-to-action.jpg" alt=""/></a><figcaption>
    The Programming Historian Needs YOU...to help historians digitally analyse!</figcaption></figure></p>

We've now published more than 100 lessons in English and Spanish since we launched in 2012. The project is growing faster than we could ever have imagined. But there are still significant holes in our coverage that we'd like you to help us plug. While we always remain [open to new lesson ideas on any topic related to your own work](/contribute), we'd be particularly happy to hear from prospective authors interested in tackling some of the following:


1) **What can you conclude from topic models?**

We requested this back in early 2017, but no one has yet written it, so we're putting out the plea again: we've got a great lesson on how to [conduct a topic model using MALLET](/en/lessons/topic-modeling-and-mallet). It's been extraordinarily popular over the years. But we're still not seeing enough historians (and humanists) actually publishing topic-model-based research results. If you've done so, please write us a tutorial on how others can do so too. This is a great opportunity to share the HOW of your article (all the bits the peer reviewers told you to take out so you could focus on the WHAT).


2) **How do you conduct spatial clustering of geographic data?**

Another re-request from our wish-list in 2017. We've got a great set of [introductory mapping lessons](/en/lessons/googlemaps-googleearth), and while they are great for teaching how to make nice visualisations, we've not yet branched deeply enough into more advanced analysis skills. One of the most useful is the application of clustering algorithms, which identify logical groups of individual points in geographic space. Useful for forming conclusions on anything from trade to migration. But like with all analyses, it's a space (no pun intended) fraught with pitfalls for the uninitiated. We're looking for a great introduction that highlights both the strengths and the challenges of this form of analysis.

3) **When do you know your network analysis is meaningful?**

Again, one that we asked for previously, but haven't yet seen. Ok, so we've built a great [network diagram](/en/lessons/creating-network-diagrams-from-historical-sources). How do we move to the next step and form meaningful conclusions? This is about starting with a graph and shifting into analysis mode. If you can help our readers take that step, we want to hear from you.

4) **TF-IDF to Historical Research**

And the last of our unfulfilled requests: let's talk about meaningful words. Term Frequency - Inverse Document Frequency is a well known means of identifying words that appear more often than we might expect in a given document. It's one of the ways we know what a document is about. Let's take this to the next step and teach readers how this fairly simple statistic about meaningful words can turn into meaningful research outputs. If you've published on historical lingustics (as in #1 above), we'd love to hear from you on the HOW TO of your wonderful paper.

5) **Space Syntax of Historical Data**

After having seen a great workshop by Katrina Navickas on [Space Syntax](https://ihrdighist.blogs.sas.ac.uk/2018/04/16/22-may-2018-workshop-using-space-syntax-methods-to-explore-the-distribution-of-meeting-places-in-19th-century-historic-maps/) we'd like to learn more about it and how historians can apply this geographical approach in their research.

6) **How to Publish Digital Scholarly Editions using a Native XML Database**

Digital scholarly editions are often modelled as XML documents. Although there are some publication tools such available, the options can be bewildering and the solutions may not fit a user's particular needs. Keeping with our open ethos, we'd like to see someone take readers through an open source solution that gives them a sustainable and flexible way to publish their digital edition.

7) **How to Analyse Audio Artefacts**
We have one lesson on how to use [Audacity](/en/lessons/editing-audio-with-audacity) to edit audio files and another on how to transform you [transform your data into audio](/en/lessons/sonification) to better understand it. But you can do much more! How are you using tools to get quantifiable data about your audio artefacts? Or, how can you use machine learning techniques to produce new understandings of an audio collection?


If you are interested in taking up our challenge, please get in touch with one of our editors. We'd be happy to talk it through with you.
